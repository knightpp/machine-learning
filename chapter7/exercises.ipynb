{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises for chapter 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix\n",
    "\n",
    "| Model      | Predicted Animal    | Predicted Not Animal |\n",
    "| ---------- | ------------------- | -------------------- |\n",
    "| Animal     | 3 (True positives)  | 2 (false negatives)  |\n",
    "| Not Animal | 1 (false positives) | 4 (true negatives)   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    # class,        is animal?, prediction\n",
    "    [\"pig\",         1,          1],\n",
    "    [\"cow\",         1,          1],\n",
    "    [\"planet\",      0,          1],\n",
    "    [\"penguin\",     1,          1],\n",
    "    [\"clock\",       0,          0],\n",
    "    [\"snail\",       1,          0],\n",
    "    [\"whale\",       1,          0],\n",
    "    [\"book\",        0,          0],\n",
    "    [\"ball\",        0,          0],\n",
    "    [\"strawberry\",  0,          0],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.\n",
    "\n",
    "> The accuracy of a model is the percentage of times that a model is correct. In other words, it is the ratio between the number of correctly predicted data points and the total number of data points.\n",
    "\n",
    "$$ Accuracy = \\frac{7}{10} = 0.7 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\n",
    "\n",
    "> Recall: Among the positive examples, how many did we correctly classify?\n",
    "\n",
    "$$ Recall = \\frac{True\\ positives}{True\\ positives + False \\ negatives } $$\n",
    "\n",
    "$$ Recall = \\frac{3}{5} = 0.6 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.\n",
    "> Precision: Among the examples we classified as positive, how many did we correctly classify?\n",
    "$$ Precision = \\frac{True\\ positives}{True\\ positives + False\\ positives } $$\n",
    "\n",
    "$$ Precision = \\frac{Predictions_{correct}}{Predictions_1} $$\n",
    "\n",
    "$$ Precision = \\frac{3}{4} = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d.\n",
    "\n",
    "> $F_1$ score is a harmonic mean of precision and recall\n",
    "\n",
    "$$ F_1 = \\frac{2PR}{P+R} $$\n",
    "\n",
    "$$ F_1 = \\frac{2 \\cdot 0.75 \\cdot 0.6}{0.75 + 0.6} = \\frac{0.9}{1.35} \\approx 0.66 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e.\n",
    "\n",
    "This isn't a good model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
