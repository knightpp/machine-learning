{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises for chapter 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix\n",
    "\n",
    "| Model      | Predicted Animal    | Predicted Not Animal |\n",
    "| ---------- | ------------------- | -------------------- |\n",
    "| Animal     | 3 (True positives)  | 2 (false negatives)  |\n",
    "| Not Animal | 1 (false positives) | 4 (true negatives)   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    # class,        is animal?, prediction\n",
    "    [\"pig\",         1,          1],\n",
    "    [\"cow\",         1,          1],\n",
    "    [\"planet\",      0,          1],\n",
    "    [\"penguin\",     1,          1],\n",
    "    [\"clock\",       0,          0],\n",
    "    [\"snail\",       1,          0],\n",
    "    [\"whale\",       1,          0],\n",
    "    [\"book\",        0,          0],\n",
    "    [\"ball\",        0,          0],\n",
    "    [\"strawberry\",  0,          0],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.\n",
    "\n",
    "> The accuracy of a model is the percentage of times that a model is correct. In other words, it is the ratio between the number of correctly predicted data points and the total number of data points.\n",
    "\n",
    "$$ Accuracy = \\frac{7}{10} = 0.7 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\n",
    "\n",
    "> Recall: Among the positive examples, how many did we correctly classify?\n",
    "\n",
    "$$ Recall = \\frac{True\\ positives}{True\\ positives + False \\ negatives } $$\n",
    "\n",
    "$$ Recall = \\frac{3}{5} = 0.6 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.\n",
    "> Precision: Among the examples we classified as positive, how many did we correctly classify?\n",
    "$$ Precision = \\frac{True\\ positives}{True\\ positives + False\\ positives } $$\n",
    "\n",
    "$$ Precision = \\frac{Predictions_{correct}}{Predictions_1} $$\n",
    "\n",
    "$$ Precision = \\frac{3}{4} = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d.\n",
    "\n",
    "> $F_1$ score is a harmonic mean of precision and recall\n",
    "\n",
    "$$ F_1 = \\frac{2PR}{P+R} $$\n",
    "\n",
    "$$ F_1 = \\frac{2 \\cdot 0.75 \\cdot 0.6}{0.75 + 0.6} = \\frac{0.9}{1.35} \\approx 0.66 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e.\n",
    "\n",
    "This isn't a good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.2\n",
    "\n",
    "Confusion matrix\n",
    "\n",
    "|            | Predicted Sick      | Predicted Healthy    |\n",
    "| ---------- | ------------------- | -------------------- |\n",
    "| Sick       | 120 (True positives)  | 22 (false negatives)  |\n",
    "| Healthy    | 63 (false positives) | 795 (true negatives)   |\n",
    "\n",
    "\n",
    "Sensitivity\n",
    "\n",
    "> Sensitivity (true positive rate): the capacity of the test to identify the positively labeled points.\n",
    "This is the ratio between the number of true positives and the total number of positives. (Note:\n",
    "this is the same as recall).\n",
    "\n",
    "$$ Sensitivity = \\frac{120}{120+22} = 0.8450 $$\n",
    "\n",
    "Specificity\n",
    "\n",
    "> Specificity (true negative rate): the capacity of the test to identify the negatively labeled points.\n",
    "This is the ratio between the number of true negatives and the total number of negatives.\n",
    "\n",
    "$$ Specificity = \\frac{795}{795+63} = 0.92 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.3\n",
    "\n",
    "1. Movie recommendation (will watch a movie?)\n",
    "   1. False negative is worse\n",
    "   2. Recall\n",
    "2. Image detection (image contains a pedestrian?)\n",
    "   1. False negative is worse\n",
    "   2. Recall\n",
    "3. Voice assistant (user gave it an order?)\n",
    "   1. False positives is worse\n",
    "   2. Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7.4\n",
    "\n",
    "> When $\\beta \\to 0$ it is full precision\n",
    ">\n",
    "> When $\\beta \\to \\infty$ it is full recall\n",
    "\n",
    "1. $\\beta > 1$\n",
    "2. $\\beta = 1$\n",
    "3. $\\beta < 1$\n",
    "4. $\\beta < 1$\n",
    "5. $\\beta < 1$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
